import os
import sys
import zipfile
from datetime import datetime

import tensorflow as tf
from tensorflow import keras
import tensorflow_addons as tfa

from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img # pour preprocessing img et plot img validation
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout
from tensorflow.keras.models import Model # pour compilation model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import RMSprop

from sklearn.model_selection import cross_val_predict, cross_val_score # pour validation model
from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, f1_score, precision_score, recall_score # pour evaluation prédiction model
from sklearn.linear_model import SGDClassifier

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# =============================================================================
# PARAMETRES MODEL
# =============================================================================

data_dir = "C:/Users/User/Desktop/MASTER/M2/MLB/PROJET/" # directory for images
print(os.listdir(data_dir))

# Vérifier si le fichier ZIP existe et si le dossier de destination n'existe pas
if os.path.isfile(data_dir + "clouds.zip") and not os.path.isdir(data_dir + "clouds"):
    print('unzip')
    # Extraire le fichier ZIP
    with zipfile.ZipFile(data_dir + "clouds.zip", 'r') as zip_ref:
        zip_ref.extractall(data_dir + "clouds")  # Extraire dans un répertoire "clouds"
else:
    print("data directory already ready")

img_width, img_height = 256, 256
nb_class = 4 # clear / partly couldy / couldy / haze
class_names = ["clear","partly_couldy","cloudy","haze"]
epoch_mod = 2 # nb de fois où les input sont pris en compte
batch_size_mod = 128 # nb d'échantillons traités ensembles. Après avoir traité tout les lots = une époch complète

save_mod_dir = "C:/Users/User/Desktop/MASTER/M2/MLB/PROJET/models_trained/"

# =============================================================================
# CREATION DATA IMG / TRAITEMENT IMG
# =============================================================================

### DATA TRAIN ET VALID 

# Creation objet pour creation data train et data valid
train_data = ImageDataGenerator(
    rescale = 1./255, # transformation valeurs rgb en float
    validation_split = 0.25, # 25 % de data de validation
    # horizontal_flip = True, # autre param de modif si besoin
    # vertical_flip = True,
    # zoom_range = 0.15,
    # width_shift_range = 0.15,
    # height_shift_range = 0.15,
    # rotation_range = 15
)


# Appel de l'objet pour création data_train et data validation
# Creation data train sur 75% data tot
train_generator = train_data.flow_from_directory(
    data_dir + "clouds",
    target_size = (img_width,img_height),
    color_mode = 'rgb',
    batch_size = batch_size_mod, 
    class_mode = "sparse", # fonction de perte => cross entropy
    subset = "training", # "training" ou "validation"
    shuffle = True, #  empeche le modèle d'apprendre sur ordre des échantillons
    )

# Creation data validation sur 25% data tot
valid_generator = train_data.flow_from_directory(
    data_dir + "clouds",
    target_size = (img_width,img_height),
    batch_size = batch_size_mod,
    class_mode = "sparse",
    subset = 'validation',
    shuffle = False
)

### DATA TEST

# Creation objet pour creation data test
test_data = ImageDataGenerator(
    rescale=1./255
    )

# Creation data test
test_generator = test_data.flow_from_directory(
    data_dir + "clouds",
    target_size = (256, 256),
    batch_size = 1,
    class_mode = "sparse",
    shuffle = False
)

# nombre d'images pour chaque dataset
print("train : ", len(train_generator.filenames))
print("valid : ", len(valid_generator.filenames))
print("test  : ", len(test_generator.filenames))

# nb de classes détéctés
print("nb classes : ", train_generator.class_indices)

# A VOIR /!\ données déséquilibrés dans chaque classes ?! Si oui utiliser courbe precision/rappel pour validation :
class_folders = os.listdir(data_dir + "clouds")

# Compter les fichiers dans chaque sous-dossier (classe)
for class_folder in class_folders:
    class_path = os.path.join(data_dir + "clouds", class_folder)
    if os.path.isdir(class_path):
        file_count = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])
        print(f"Classe {class_folder}: {file_count} images")

# classe fortement déséquilibré pour clear et un peu pour partly_cloudy
# Classe clear: 28432 images
# Classe cloudy: 2089 images
# Classe haze: 2697 images
# Classe partly_cloudy: 7261 images

#### /!\ Dataset assez grand pour ne pas avoir à faire de la validation croisée !

###### Afficher image ---------------------------------------------------------
images, labels = next(train_generator)

image = images[0]
label = labels[0]

class_index = np.argmax(label)

plt.imshow(image)  
plt.axis('off')
plt.title(round(label))
plt.show()
# clear : 0, 
# cloudy : 1
# haze : 2
# partly_cloudy : 3
###### ------------------------------------------------------------------------

# =============================================================================
# CREATION ARCHITECTURE MODEL
# =============================================================================

# Création d'un réseau de neurones vide 
model = keras.models.Sequential()

# Input 
model_input = Input(shape=(img_width, img_height,3)) # 3 car RVB

# 1ère couche - PARTIE 1 : convolution + activation ReLU + max-pooling + Dropout
model = Conv2D(16, (5,5), padding = "same")(model_input)
model = Activation("relu")(model)
model = MaxPooling2D(pool_size=(2,2))(model) # 2,2 taille par défault
#regularisation pr eviter le surapprentissage, permet d'éteindre des neurones à chaque époch. Valeur = % de neurones à éteindre => à mettre entre couche dense et parfois entre couches convolutionelles
model = Dropout(0.2)(model) 

# 1ère couche - PARTIE 2: convolution + activation ReLU + max-pooling + Dropout
model = Conv2D(16, (3,3), padding = "same")(model)
model = Activation("relu")(model)
model = MaxPooling2D(pool_size = (2,2))(model)
model = Dropout(0.2)(model) 

# 2ème couche : convolution + activation ReLU + max-pooling + Dropout
model = Conv2D(32, (3,3), padding = "same")(model)
model = Activation("relu")(model)
model = MaxPooling2D(pool_size = (2,2))(model)
model = Dropout(0.2)(model) 

# 3ème couche : applatissement + couche Dense + activation ReLU + Dropout
model = Flatten()(model)
model = Dense(16)(model)
model = Activation("relu")(model)
model = Dropout(0.2)(model) 

# Output
model = Dense(nb_class)(model)
model_output = Activation("softmax")(model)

# summary
model_final = Model(model_input, model_output)
model_final.summary()

# =============================================================================
# COMPILATION MODEL
# =============================================================================

# COMPILATION AVEC SGD
# model_final.compile(optimizer= SGD(learning_rate=0.001, momentum=0.9), # jouer sur les paramètres
#                     loss = "sparse_categorical_crossentropy",
#                     metrics = ["accuracy"]) # ajouter autre métriques ?

# momentum = 90 % => Indique que 90 % de la mise à jour précédente sera pris en compte lors de la mise à jour actuelle des poids

# COMPILATION AVEC RSMPROP (permet d'ajuste le taux d'apprentissage en continu)

model_final.compile(optimizer=RMSprop(learning_rate=0.001, rho=0.9),  # rho de RMSprop joue le même rôle que le momentum : 
                    loss="sparse_categorical_crossentropy",
                    metrics = [
                    'accuracy',
                    tfa.metrics.F1Score(num_classes=num_classes, average='macro'),  # ou 'micro' selon votre besoin
                    tfa.metrics.CohenKappa(),
                    tfa.metrics.Precision(),
                    tfa.metrics.Recall()
                    ]
                    )

# =============================================================================
# ENTRAINEMENT MODEL
# =============================================================================

## si bug tensorboard : 
# - kill processus : netstat -aon | findstr :6006 ##### puis : taskkill /PID <PID> /F
# - relancer le code : F5

#### implémentation tensorboard -----------------------------------------------
root_logdir = os.path.join(os.curdir, "my_logs")
def get_run_logdir():
 import time
 run_id = time.strftime("run_%Y_%m_%d-%H_%M_%S")
 return os.path.join(root_logdir, run_id)
run_logdir = get_run_logdir()
tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)
#### --------------------------------------------------------------------------

# Lancer TensorBoard automatiquement
%reload_ext tensorboard
%tensorboard --logdir ./my_logs --port=6006

# option de réduction d'apprentissage lorsqu'il n'y a plus de progrès
lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=4)

# entrainemtn du model
history = model_final.fit(
              train_generator,
              epochs = epoch_mod,
              validation_data = valid_generator,
              callbacks=[tensorboard_cb,lr_scheduler] # tensorboard_cb pour appel tensorboard. On peut aussi ajouter lr_scheduler
              )

#### --------------------------------------------------------------------------
# 1. Aller sur : http://localhost:6006
# 2. mettre en temps réel les calculs dans paramètres Tensorboard
# attention les courbe en opacité basse sont les valeurs réelle. En couleur c'est juste un smooth
#### --------------------------------------------------------------------------

# Sauvegarder le modèle entraîné
date_str = datetime.now().strftime("%d_%m")  # JJ_MM
model_final.save(save_mod_dir + f"cloud_classifier_model_{date_str}.h5")
# model = keras.models.load_model("my_keras_model.h5") # pour load un model

sys.exit()

# =============================================================================
# VALIDATION MODEL
# =============================================================================

# VALIDATION sur des données de validation 

# Evolution accuracy => historique du modèle
# capacité à bien prédire qui évolue
plt.plot(history.history['accuracy'], label='train accuracy')
plt.plot(history.history['val_accuracy'], label='valid accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.show()

# Evolution Fonction de perte (CE) => historique du modèle
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

# Evolution Précision
plt.plot(history.history['precision'], label='Precision')
plt.plot(history.history['val_precision'], label='Validation Precision')
plt.title('Training and Validation Precision')
plt.legend()
plt.show()

# Evolution Rappel
plt.plot(history.history['recall'], label='Recall')
plt.plot(history.history['val_recall'], label='Validation Recall')
plt.title('Training and Validation Recall')
plt.legend()
plt.show()

# Evolution F1 Score
plt.plot(history.history['f1_score'], label='F1 Score')
plt.plot(history.history['val_f1_score'], label='Validation F1 Score')
plt.title('Training and Validation F1 Score')
plt.legend()
plt.show()

# interprétation fct loss : 
#    - Train + valid diminue => good apprentissage 
#    - Train diminue + valid ré-augmente => Overfitting
#    - Train et valid restent haut => Underfitting (modèle trop simple)
#    - Fluctuation Train et Valid +> Lamda trop élevé ou mauvaises data valid


# =============================================================================
# EVALUATION ET PREDICTIONS
# =============================================================================

# faisons un binary classifier pour chaque classe
# clear : 0, 
# cloudy : 1
# haze : 2
# partly_cloudy : 3

# a changer quand code malo à jour
# recreaton generator juste pour moduler taille lots
train_generator = test_data.flow_from_directory(
    data_dir + "clouds",
    target_size = (256, 256),
    batch_size = 500,
    class_mode = "sparse",
    shuffle = True
    )

# Creation data test
test_generator = test_data.flow_from_directory(
    data_dir + "clouds",
    target_size = (256, 256),
    batch_size = 500,
    class_mode = "sparse",
    shuffle = False
)

images_train, labels_train = next(train_generator) # 500 éléments = taille du batch
images_test, labels_test = next(test_generator) # 500 éléments = taille du batch

# Aplatir les images pour le classificateur
n_samples, height, width, n_channels = images_train.shape
images_train_flat = images_train.reshape(n_samples, height * width * n_channels)

# Appliquer la même transformation sur le test
n_samples_test = images_test.shape[0]
images_test_flat = images_test.reshape(n_samples_test, height * width * n_channels)

Y_train = labels_train
Y_test = labels_test

y_train_0 = (labels_train == 0) 
y_test_0 = (labels_test == 0)

y_train_1 = (labels_train == 1) 
y_test_1 = (labels_test == 1)

y_train_2 = (labels_train == 2) 
y_test_2 = (labels_test == 2)

y_train_3 = (labels_train == 3) 
y_test_3 = (labels_test == 3)

y_train = [y_train_0,y_train_1,y_train_2,y_train_3]

# binary classifier pour chaque classe
sgd_clf = SGDClassifier(random_state=42) # seed

# exemple binary classifier pour classer les clears "0"
some_img = images_train_flat[0] # img
sgd_clf.fit(images_train_flat, 
            y_train_0) # apprentissage
sgd_clf.predict([some_img]) # prediction sur une image

nb_k_folds = 3
# test validation croisée
cross_val_score(sgd_clf, images_train_flat, y_train_0, cv=nb_k_folds, scoring="accuracy")


###### EVALUATION sur données test
### 1. Accuracy
test_loss, test_accuracy = model_final.evaluate(test_generator)
print(f"Test loss : {test_loss}")
print(f"Test accuracy: {test_accuracy}")

### 2. Matrice de confusion  ----------------------------------------------------------------------------------------------------------------

# TOT
y_train_pred_tot = cross_val_predict(sgd_clf, images_train_flat, Y_train, cv=nb_k_folds) # Just like the cross_val_score() function, cross_val_predict() performs K-fold cross-validation, but instead of returning the evaluation scores, it returns the predictions made on each test fold
confusion_matrix(Y_train, y_train_pred_tot)

# clear : 0
y_train_pred_0 = cross_val_predict(sgd_clf, images_train_flat, y_train_0, cv=nb_k_folds) 
confusion_matrix(y_train_0, y_train_pred_0)

# cloudy : 1
y_train_pred_1 = cross_val_predict(sgd_clf, images_train_flat, y_train_1, cv=nb_k_folds) 
confusion_matrix(y_train_1, y_train_pred_1)

# haze : 2
y_train_pred_2 = cross_val_predict(sgd_clf, images_train_flat, y_train_2, cv=nb_k_folds) 
confusion_matrix(y_train_2, y_train_pred_2)

# partly_cloudy : 3
y_train_pred_3 = cross_val_predict(sgd_clf, images_train_flat, y_train_3, cv=nb_k_folds)
confusion_matrix(y_train_3, y_train_pred_3)


### 3. courbe precision/rappel pour validation si données déséquilibrés (c'set le cas ici) --------------------------------------------------
## score ----------------------------------------------------------------------
# Precision = proportion des vrais positifs
# Rapell/sensibilité = proportion des vrais positifs parmi toutes les instances qui sont réellement positives (vrai positif + faux négatif)

# Précision élevée :  lorsque le modèle prédit une instance comme positive, il a raison dans une grande majorité des cas.
# Rappel élevé : le modèle détecte la plupart des instances positives, même si cela signifie qu'il peut aussi classer certaines instances négatives comme positives.

# TOT
precision_score(Y_train, y_train_pred_tot)
recall_score(Y_train, y_train_pred_tot)

# clear : 0
precision_score(y_train_0, y_train_pred_0)
recall_score(y_train_0, y_train_pred_0)

# cloudy : 1
precision_score(y_train_1, y_train_pred_1)
recall_score(y_train_1, y_train_pred_1)

# haze : 2
precision_score(y_train_2, y_train_pred_2)
recall_score(y_train_2, y_train_pred_2)

# partly_cloudy : 3
precision_score(y_train_3, y_train_pred_3)
recall_score(y_train_3, y_train_pred_3)

## fig avec seuil : à faire + comprendre --------------------------------------
# Dans un contexte de classification binaire, le seuil détermine à partir de quelle probabilité on considère qu'une observation appartient à la classe positive.
# par défault, seuil = 0.5
y_scores_0 = cross_val_predict(sgd_clf, images_train_flat, y_train_0, cv=3,method="decision_function")
y_scores_1 = cross_val_predict(sgd_clf, images_train_flat, y_train_1, cv=3,method="decision_function")
y_scores_2 = cross_val_predict(sgd_clf, images_train_flat, y_train_2, cv=3,method="decision_function")
y_scores_3 = cross_val_predict(sgd_clf, images_train_flat, y_train_3, cv=3,method="decision_function")

y_scores = [y_scores_0,y_scores_1,y_scores_2,y_scores_3]

## curve : à faire ------------------------------------------------------------
# [...]

### 4. ROC curve et AUC -----------------------------------------------------------------------------------------------------------------------------
def plot_roc_curve(fpr, tpr, label=None):
 plt.plot(fpr, tpr, linewidth=2, label=label)
 plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal

for i in range(nb_class):
    fpr, tpr, thresholds = roc_curve(y_train[i], y_scores[i])
    plot_roc_curve(fpr, tpr)
    plt.title(f"ROC curve class {i}")
    plt.show()


# 5. f1 score = = moyenne harmonique de la précision et du rappel ----------------------------------------------------------------------------------------------------
# Le score F1 permet de mieux évaluer la capacité du modèle à identifier correctement la/les classe(s) minoritaire(s)

# clear : 0
f1_score(y_train_0, y_train_pred_0)

# cloudy : 1
f1_score(y_train_1, y_train_pred_1)

# haze : 2
f1_score(y_train_2, y_train_pred_2)

# partly_cloudy : 3
f1_score(y_train_3, y_train_pred_3)



