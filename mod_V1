import os
import sys
import zipfile
import datetime

import tensorflow as tf
from tensorflow import keras

from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img # pour preprocessing img et plot img validation
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout
from tensorflow.keras.models import Model # pour compilation model
from tensorflow.keras.optimizers import SGD

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# =============================================================================
# PARAMETRES MODEL
# =============================================================================

data_dir = "C:/Users/User/Desktop/MASTER/M2/MLB/PROJET/" # directory for images
print(os.listdir(data_dir))

# Vérifier si le fichier ZIP existe et si le dossier de destination n'existe pas
if os.path.isfile(data_dir + "clouds.zip") and not os.path.isdir(data_dir + "clouds"):
    print('unzip')
    # Extraire le fichier ZIP
    with zipfile.ZipFile(data_dir + "clouds.zip", 'r') as zip_ref:
        zip_ref.extractall(data_dir + "clouds")  # Extraire dans un répertoire "clouds"
else:
    print("data directory already ready")


img_width, img_height = 256, 256
nb_class = 4 # clear / partly couldy / couldy / haze
class_names = ["clear","partly_couldy","cloudy","haze"]
epoch_mod = 1 # nb de fois où les input sont pris en compte
batch_size_mod = 128 # nb d'échantillons trait"s ensembles. Après avoir traité tout les lots = une époch complète

save_mod_dir = "C:/Users/User/Desktop/MASTER/M2/MLB/PROJET/"

# =============================================================================
# CREATION DATA IMG / TRAITEMENT IMG
# =============================================================================

# Creation objet pour creation data train et data valid
train_data = ImageDataGenerator(
    rescale = 1./255, # transformation valeurs rgb en float
    validation_split = 0.25, # 25 % de data de validation
    # horizontal_flip = True, # autre param de modif si besoin
    # vertical_flip = True,
    # zoom_range = 0.15,
    # width_shift_range = 0.15,
    # height_shift_range = 0.15,
    # rotation_range = 15
)

# Creation objet pour creation data test
test_data = ImageDataGenerator(
    rescale=1./255
    )

# Appel de l'objet pour création data_train et data validation
# Creation data train sur 75% data tot
train_generator = train_data.flow_from_directory(
    data_dir + "clouds",
    target_size = (img_width,img_height),
    color_mode = 'rgb',
    batch_size = batch_size_mod, 
    class_mode = "categorical", # fonction de perte => cross entropy
    subset = "training", # "training" ou "validation"
    shuffle = True,
    )

# Creation data validation sur 25% data tot
valid_generator = train_data.flow_from_directory(
    data_dir + "clouds",
    target_size = (img_width,img_height),
    batch_size = batch_size_mod,
    class_mode = "categorical",
    subset = 'validation',
    shuffle = False
)

# Creation data test
test_generator = test_data.flow_from_directory(
    data_dir + "clouds",
    target_size=(256, 256) ,
    batch_size=1,
    #class_mode="binary",
    shuffle=False
)

# nombre d'images pour chaque dataset
print("train : ", len(train_generator.filenames))
print("valid : ", len(valid_generator.filenames))
print("test  : ", len(test_generator.filenames))

# nb de classes détéctés
print("nb classes : ", train_generator.class_indices)

# A VOIR /!\ données déséquilibrés dans chaque classes ?! Si oui utiliser courbe precision/rappel pour validation

###### Afficher image ---------------------------------------------------------
images, labels = next(train_generator)

image = images[0]
label = labels[0]

class_index = np.argmax(label)

plt.imshow(image)  
plt.axis('off')  
plt.show()  
###### ------------------------------------------------------------------------

# =============================================================================
# CREATION ARCHITECTURE MODEL
# =============================================================================

# Création d'un réseau de neurones vide 
model = keras.models.Sequential()

# Input 
model_input = Input(shape=(img_width, img_height,3)) # 3 car RVB

# 1ère couche - PARTIE 1 : convolution + activation ReLU + max-pooling + Dropout
model = Conv2D(16, (5,5), padding = "same")(model_input)
model = Activation("relu")(model)
model = MaxPooling2D(pool_size=(2,2))(model) # 2,2 taille par défault
#regularisation pr eviter le surapprentissage, permet d'éteindre des neurones à chaque époch. Valeur = % de neurones à éteindre => à mettre entre couche dense et parfois entre couches convolutionelles
model = Dropout(0.2)(model) 

# 1ère couche - PARTIE 2: convolution + activation ReLU + max-pooling + Dropout
model = Conv2D(16, (3,3), padding = "same")(model)
model = Activation("relu")(model)
model = MaxPooling2D(pool_size = (2,2))(model)
model = Dropout(0.2)(model) 

# 2ème couche : Dense + activation ReLU + convolution + activation ReLU + max-pooling + Dropout
model = Dense(64)(model)
model = Activation("relu")(model)
model = Conv2D(32, (3,3), padding = "same")(model)
model = Activation("relu")(model)
model = MaxPooling2D(pool_size = (2,2))(model)
model = Dropout(0.2)(model) 

# 3ème couche : applatissement + couche Dense + activation ReLU + Dropout
model = Flatten()(model)
model = Dense(16)(model)
model = Activation("relu")(model)
model = Dropout(0.2)(model) 

# Output
model = Dense(nb_class)(model)
model_output = Activation("softmax")(model)

# summary
model_final = Model(model_input, model_output)
model_final.summary()

# =============================================================================
# COMPILATION MODEL
# =============================================================================

model_final.compile(optimizer= SGD(learning_rate=0.001, momentum=0.9), # jouer sur les paramètres
                    loss = "categorical_crossentropy", # RMSprop ??
                    metrics = ["accuracy"]) # ajouter autre métriques ?
# momentum = 90 % => Indique que 90 % de la mise à jour précédente sera pris en compte lors de la mise à jour actuelle des poids

# =============================================================================
# ENTRAINEMENT MODEL
# =============================================================================

step_size_train = train_generator.n//train_generator.batch_size # nombre d'étapes nécessaires pour parcourir l'ensemble des données d'entraînement en une époch
lenght_valid = 5 # plus c'est haut et moin on a de data de validation
nb_validation_samples = valid_generator.n//valid_generator.batch_size//lenght_valid # nb d'échantillons de validation utilisé pour validation en divisant encore si on veut une vitesse plus rapide
print(step_size_train)
print(nb_validation_samples)

#### implémentation tensorboard -----------------------------------------------
root_logdir = os.path.join(os.curdir, "my_logs")
def get_run_logdir():
 import time
 run_id = time.strftime("run_%Y_%m_%d-%H_%M_%S")
 return os.path.join(root_logdir, run_id)
run_logdir = get_run_logdir()
tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)
#### --------------------------------------------------------------------------

#### --------------------------------------------------------------------------
# 1. éxécuter la commande dans la console : !tensorboard --logdir=./my_logs --port=6006
# 2. puis aller sur : http://localhost:6006
# (3. mettre en temps réel les calculs dans paramètres Tensorboard)
# 4. ourvrir une nouvelle console pour l'éxécution du code
#### --------------------------------------------------------------------------

sys.exit()

# option de réduction d'apprentissage lorsqu'il n'y a plus de progrès
lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10)

history = model_final.fit(
              train_generator,
              steps_per_epoch=step_size_train, # nb étapes à effectuer dans chaque époque. Cela signifie que le modèle va traiter "step_size_train" lots d'échantillons par époch.
              epochs = epoch_mod,
              validation_data = valid_generator,
              validation_steps=nb_validation_samples,
              callbacks=[tensorboard_cb] # pour appel tensorboard, on peut aussi ajouter notre lr_scheduler
              )


# Sauvegarder le modèle entraîné
model_final.save(save_mod_dir + "cloud_classifier_model.h5")
# model = keras.models.load_model("my_keras_model.h5") # pour load un model

# =============================================================================
# VALIDATION ET EVALUATION MODEL
# =============================================================================

# sur des données de validation
val_loss, val_accuracy = model_final.evaluate(valid_generator)
print(f"Validation loss : {val_loss}")
print(f"Validation accuracy: {val_accuracy}")

# sur des données test
test_loss, test_acc = model_final.evaluate(test_generator)
print(f"Test loss: {test_loss}")
print(f"Test accuracy: {test_acc}")

# courbe precision/rappel pour validation si données déséquilibrés


# Tracer la courbe d'entraînement et de validation
plt.plot(history.history['accuracy'], label='train accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

# 









# retrouver labl img à partir de leurs directory


# last_img = 17855
# last_img  = 10
# f = open('myfile.csv', 'w') 
# f.write("name;prediction\n")
# for i in range(last_img): 
#   filename = str(i)+".jpg"
#   img = load_img("/content/gdrive/My Drive/clouds/"+filename)  # this is a PIL image
#   x = img_to_array(img) 
#   x = x/255
#   x = x.reshape((1,) + x.shape) 
#   predict = model_final.predict(x)
#   #print(filename+";"+str(int(predict>.5)))
#   f.write(filename+";"+str(int(predict>.5))+"\n")
# f.close()
# files.download('myfile.csv')


